e.g. bring in the powell center synthesis or the NWQP set.
these sets won't change, so we don't need to manage them along with the "normal" sp data.
instead, they get their own database tables, and their own special workarounds so that they can be vizzed etc without slowing things down.
this example was created while incorporating the nwqp set, so "NWQP" or "nwqp" is the word that will change if this has to happen again.

make db table
    execute in sql:
        create table nwqp like data;
    write R script to insert new data
        powell example is in git/streampulse/model/ancillary
        nwqp example is git/streampulse/other_projects/nwqp_ingest/src/munge.R
visualize inputs
    copy sp/site_update_stored_procedure_nwqp.sql and change the name "nwqp" within
    make a new script like scheduled_scripts/update_nwqp_site_data.py and run it
    update visualize and get_viz funcs in app.py
    update html and js in templates/visualize.html (search "nwqp")
    update interquartile() in app.py (won't work till you create "model rds" objects
visualize results
    manufacture rds files like those returned by streammetabolizer
        this happens in streampulse/other_projects/nwqp_ingest/src/munge.R
        could also use the powell version of this, which starts from model output objects and is here: model_viz/powell_data/structure_powell_data.R
    update __ in app.py
kernel density plot?
sitelist
    update title_mapping in app.py/sitelist()
        and the regex just above that
download
download_bulk
map
    update app.py/site_map()
    update templates/map.html
        don't forget the legend string
ignore these:
    app.py/query_available_results()
    app.py/request_results()
    app.py/allXX_download()
    app.py/request_predictions()

run the script that updates varlist, firstrecord, lastrecord in site data
build rds files so we can see model results
copy shiny/model_viz/<results folder with manufactured rds objects> to server

